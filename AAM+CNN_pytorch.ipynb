{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d7e6440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1dbc5efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Đang sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "EMOTION_LABELS = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "TRAIN_CSV = \"dataset_csv/fer2013_train.csv\"\n",
    "TEST_CSV  = \"dataset_csv/fer2013_test.csv\"\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\">>> Đang sử dụng thiết bị: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cbc33e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CÁC HÀM XỬ LÝ HÌNH HỌC (GIỮ NGUYÊN) ---\n",
    "def center_scale_landmarks(X):\n",
    "    X_cs = []\n",
    "    if X.ndim == 1: X = X.reshape(1, -1)\n",
    "    for s in X:\n",
    "        xs, ys = s[::2], s[1::2]\n",
    "        mean_x, mean_y = xs.mean(), ys.mean()\n",
    "        scale = max(xs.max()-xs.min(), ys.max()-ys.min())\n",
    "        if scale == 0: scale = 1\n",
    "        X_cs.append(np.column_stack([(xs-mean_x)/scale, (ys-mean_y)/scale]).flatten())\n",
    "    return np.array(X_cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d02e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_face_mp(img, src_lms_norm, mean_lms_norm, size=(48,48)):\n",
    "    src_pts = src_lms_norm.reshape(-1, 2) * size[0]\n",
    "    dst_pts = mean_lms_norm.reshape(-1, 2) * size[0]\n",
    "    \n",
    "    if len(img.shape) == 3: img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else: img_gray = img\n",
    "        \n",
    "    M, _ = cv2.estimateAffinePartial2D(src_pts, dst_pts)\n",
    "    if M is not None:\n",
    "        warped = cv2.warpAffine(img_gray, M, size)\n",
    "    else:\n",
    "        warped = cv2.resize(img_gray, size)\n",
    "    \n",
    "    # Chuẩn hóa về [0, 1]\n",
    "    warped = warped.astype('float32') / 255.0\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f5bb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DATASET CLASS (QUAN TRỌNG) ---\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, csv_path, pca, scaler, mean_shape, is_train=False):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.paths = self.df.iloc[:, 0].values\n",
    "        self.labels = self.df.iloc[:, 2].values\n",
    "        self.lms = self.df.iloc[:, 4:].values.astype(np.float32)\n",
    "        \n",
    "        self.pca = pca\n",
    "        self.scaler = scaler\n",
    "        self.mean_shape = mean_shape\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Đọc ảnh\n",
    "        img_path = self.paths[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            # Nếu lỗi đọc ảnh, trả về ảnh đen (để tránh crash code)\n",
    "            img = np.zeros((48, 48, 3), dtype=np.uint8)\n",
    "            \n",
    "        label = self.labels[idx]\n",
    "        lm_raw = self.lms[idx]\n",
    "\n",
    "        # 2. Augmentation (Chỉ chỉnh sáng, KHÔNG FLIP để tránh lỗi landmark)\n",
    "        if self.is_train:\n",
    "            # Brightness / Contrast\n",
    "            alpha = np.random.uniform(0.8, 1.2)\n",
    "            beta = np.random.randint(-20, 20)\n",
    "            img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "            \n",
    "            # Noise\n",
    "            if np.random.rand() > 0.7:\n",
    "                noise = np.random.normal(0, 5, img.shape).astype(np.uint8)\n",
    "                img = cv2.add(img, noise)\n",
    "\n",
    "        # 3. Xử lý Landmark & Warp\n",
    "        lm_norm = lm_raw / 48.0\n",
    "        warped_img = warp_face_mp(img, lm_norm, self.mean_shape, IMG_SIZE)\n",
    "        \n",
    "        # 4. Xử lý Shape Vector\n",
    "        lm_cs = center_scale_landmarks(lm_raw.reshape(1, -1))\n",
    "        shape_vec = self.scaler.transform(self.pca.transform(lm_cs)).flatten()\n",
    "\n",
    "        # 5. Chuyển sang Tensor\n",
    "        # Ảnh: (H, W) -> (1, H, W) cho PyTorch Conv2d\n",
    "        img_tensor = torch.tensor(warped_img, dtype=torch.float32).unsqueeze(0)\n",
    "        shape_tensor = torch.tensor(shape_vec, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img_tensor, shape_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "563606fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. MODEL DEFINITION (PYTORCH) ---\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, shape_input_dim, num_classes=7):\n",
    "        super(HybridModel, self).__init__()\n",
    "        \n",
    "        # Nhánh 1: CNN (Texture)\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 24x24\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 12x12\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 6x6\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        \n",
    "        # Nhánh 2: Shape (Dense)\n",
    "        self.shape_fc = nn.Sequential(\n",
    "            nn.Linear(shape_input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Kết hợp\n",
    "        # CNN Output: 256 channels * 6 * 6 = 9216\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6 + 128, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_shape):\n",
    "        x1 = self.features(x_img)\n",
    "        x1 = x1.view(x1.size(0), -1) # Flatten\n",
    "        \n",
    "        x2 = self.shape_fc(x_shape)\n",
    "        \n",
    "        combined = torch.cat((x1, x2), dim=1)\n",
    "        out = self.classifier(combined)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f2689c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def train_pipeline():\n",
    "    print(\"\\n>>> CHUẨN BỊ DỮ LIỆU (CHIẾN LƯỢC: OVERSAMPLING)...\")\n",
    "    \n",
    "    # 1. PCA & Scaler (Giữ nguyên)\n",
    "    print(\" - Đang fit PCA & Scaler...\")\n",
    "    df_train = pd.read_csv(TRAIN_CSV)\n",
    "    X_lms_train = df_train.iloc[:, 4:].values.astype(np.float32)\n",
    "    \n",
    "    # Lấy danh sách nhãn để tính toán sampler\n",
    "    y_train_raw = df_train.iloc[:, 2].values\n",
    "    \n",
    "    X_cs = center_scale_landmarks(X_lms_train)\n",
    "    pca = PCA(n_components=0.99)\n",
    "    X_pca = pca.fit_transform(X_cs)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_pca)\n",
    "    \n",
    "    mean_shape_raw = X_cs.mean(axis=0)\n",
    "    mean_shape = (mean_shape_raw - mean_shape_raw.min()) / (mean_shape_raw.max() - mean_shape_raw.min())\n",
    "    \n",
    "    if not os.path.exists(\"model_mp\"): os.makedirs(\"model_mp\")\n",
    "    joblib.dump(pca, \"model_mp/shape_pca.pkl\")\n",
    "    joblib.dump(scaler, \"model_mp/shape_scaler.pkl\")\n",
    "    joblib.dump(mean_shape, \"model_mp/mean_shape.pkl\")\n",
    "\n",
    "    # 2. Tạo Dataset\n",
    "    train_dataset = FERDataset(TRAIN_CSV, pca, scaler, mean_shape, is_train=True)\n",
    "    test_dataset  = FERDataset(TEST_CSV, pca, scaler, mean_shape, is_train=False)\n",
    "    \n",
    "    # --- [QUAN TRỌNG] TẠO SAMPLER ĐỂ CÂN BẰNG DỮ LIỆU ---\n",
    "    print(\" - Đang cấu hình WeightedRandomSampler...\")\n",
    "    \n",
    "    # Đếm số lượng mẫu của từng lớp\n",
    "    class_counts = np.bincount(y_train_raw)\n",
    "    \n",
    "    # Tính trọng số: Lớp càng ít mẫu, trọng số càng cao\n",
    "    # (1.0 / count)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    \n",
    "    # Gán trọng số cho từng mẫu dữ liệu trong tập train\n",
    "    sample_weights = [class_weights[label] for label in y_train_raw]\n",
    "    sample_weights = torch.FloatTensor(sample_weights)\n",
    "    \n",
    "    # Tạo Sampler: Bốc mẫu dựa trên trọng số\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True # Cho phép bốc lặp lại (quan trọng)\n",
    "    )\n",
    "    \n",
    "    # Lưu ý: Khi dùng sampler, shuffle phải là False\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 3. Model & Loss\n",
    "    # Vì đã dùng Sampler cân bằng rồi, ta KHÔNG cần class_weight trong Loss nữa (tránh chỉnh sửa kép)\n",
    "    # Tuy nhiên, ta dùng Label Smoothing để giảm việc model quá tự tin vào Happy\n",
    "    shape_dim = X_pca.shape[1]\n",
    "    model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "    \n",
    "    # label_smoothing=0.1 giúp model bớt \"cứng đầu\", giảm overfitting\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1) \n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4) # Thêm weight_decay\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4, verbose=True)\n",
    "\n",
    "    print(\"\\n>>> BẮT ĐẦU TRAINING (CÂN BẰNG TUYỆT ĐỐI)...\")\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, (imgs, shapes, labels) in enumerate(train_loader):\n",
    "            imgs, shapes, labels = imgs.to(DEVICE), shapes.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs, shapes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        train_acc = 100 * correct / total\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        val_acc, val_loss = evaluate_model(model, test_loader, criterion)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] | Time: {end_time-start_time:.1f}s | \"\n",
    "              f\"Loss: {avg_loss:.4f} | Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Lưu model nếu tốt hơn\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"model_mp/hybrid_model_pytorch.pth\")\n",
    "            print(\"   -> Đã lưu model tốt nhất!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3957e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 3. TRAINING PIPELINE ---\n",
    "# def train_pipeline():\n",
    "#     print(\"\\n>>> CHUẨN BỊ DỮ LIỆU...\")\n",
    "    \n",
    "#     # 1. Load toàn bộ landmark Train để fit PCA trước\n",
    "#     print(\" - Đang fit PCA & Scaler...\")\n",
    "#     df_train = pd.read_csv(TRAIN_CSV)\n",
    "#     X_lms_train = df_train.iloc[:, 4:].values.astype(np.float32)\n",
    "#     y_train_raw = df_train.iloc[:, 2].values\n",
    "    \n",
    "#     # PCA & Scaler Setup\n",
    "#     X_cs = center_scale_landmarks(X_lms_train)\n",
    "#     pca = PCA(n_components=0.99)\n",
    "#     X_pca = pca.fit_transform(X_cs)\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_pca)\n",
    "    \n",
    "#     # Mean Shape\n",
    "#     mean_shape_raw = X_cs.mean(axis=0)\n",
    "#     mean_shape = (mean_shape_raw - mean_shape_raw.min()) / (mean_shape_raw.max() - mean_shape_raw.min())\n",
    "    \n",
    "#     # Lưu resources\n",
    "#     if not os.path.exists(\"model_mp\"): os.makedirs(\"model_mp\")\n",
    "#     joblib.dump(pca, \"model_mp/shape_pca.pkl\")\n",
    "#     joblib.dump(scaler, \"model_mp/shape_scaler.pkl\")\n",
    "#     joblib.dump(mean_shape, \"model_mp/mean_shape.pkl\")\n",
    "\n",
    "#     # 2. Tạo Dataset & DataLoader\n",
    "#     train_dataset = FERDataset(TRAIN_CSV, pca, scaler, mean_shape, is_train=True)\n",
    "#     test_dataset  = FERDataset(TEST_CSV, pca, scaler, mean_shape, is_train=False)\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "#     test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "#     # 3. Tính Class Weights\n",
    "#     class_weights = compute_class_weight('balanced', classes=np.unique(y_train_raw), y=y_train_raw)\n",
    "#     weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "#     print(f\" - Class Weights: {class_weights}\")\n",
    "\n",
    "#     # 4. Khởi tạo Model\n",
    "#     shape_dim = X_pca.shape[1]\n",
    "#     model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "    \n",
    "#     criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "#     print(\"\\n>>> BẮT ĐẦU TRAINING (PyTorch)...\")\n",
    "#     best_acc = 0.0\n",
    "    \n",
    "#     for epoch in range(EPOCHS):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "        \n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         for i, (imgs, shapes, labels) in enumerate(train_loader):\n",
    "#             imgs, shapes, labels = imgs.to(DEVICE), shapes.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(imgs, shapes)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "            \n",
    "#         train_acc = 100 * correct / total\n",
    "#         avg_loss = running_loss / len(train_loader)\n",
    "        \n",
    "#         # Validation\n",
    "#         val_acc, val_loss = evaluate_model(model, test_loader, criterion)\n",
    "#         scheduler.step(val_loss)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         print(f\"Epoch [{epoch+1}/{EPOCHS}] | Time: {end_time-start_time:.1f}s | \"\n",
    "#               f\"Loss: {avg_loss:.4f} | Acc: {train_acc:.2f}% | \"\n",
    "#               f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "#         if val_acc > best_acc:\n",
    "#             best_acc = val_acc\n",
    "#             torch.save(model.state_dict(), \"model_mp/hybrid_model_pytorch.pth\")\n",
    "#             print(\"   -> Đã lưu model tốt nhất!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5aa1b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, shapes, labels in loader:\n",
    "            imgs, shapes, labels = imgs.to(DEVICE), shapes.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs, shapes)\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    acc = 100 * correct / total\n",
    "    loss = running_loss / len(loader) if criterion else 0\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3e727d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance():\n",
    "    if not os.path.exists(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\"):\n",
    "        print(\"Chưa có model PyTorch!\")\n",
    "        return\n",
    "\n",
    "    # Load resources\n",
    "    pca = joblib.load(\"model_mp_main_tot_nhat/shape_pca.pkl\")\n",
    "    scaler = joblib.load(\"model_mp_main_tot_nhat/shape_scaler.pkl\")\n",
    "    mean_shape = joblib.load(\"model_mp_main_tot_nhat/mean_shape.pkl\")\n",
    "    \n",
    "    # Load Model\n",
    "    # Cần biết shape dim. Hack: lấy từ PCA\n",
    "    shape_dim = pca.n_components_\n",
    "    model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    test_dataset = FERDataset(TEST_CSV, pca, scaler, mean_shape, is_train=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\">>> Đang đánh giá...\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, shapes, labels in test_loader:\n",
    "            imgs, shapes = imgs.to(DEVICE), shapes.to(DEVICE)\n",
    "            outputs = model(imgs, shapes)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    print(classification_report(all_labels, all_preds, target_names=EMOTION_LABELS))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72b791",
   "metadata": {},
   "source": [
    "## ĐIỂM ẢNH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd7c6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam():\n",
    "    # 1. Load các tài nguyên (Model, PCA, Scaler)\n",
    "    if not os.path.exists(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\"): \n",
    "        print(\"LỖI: Chưa có file model PyTorch.\")\n",
    "        return\n",
    "    \n",
    "    pca = joblib.load(\"model_mp_main_tot_nhat/shape_pca.pkl\")\n",
    "    scaler = joblib.load(\"model_mp_main_tot_nhat/shape_scaler.pkl\")\n",
    "    mean_shape = joblib.load(\"model_mp_main_tot_nhat/mean_shape.pkl\")\n",
    "    shape_dim = pca.n_components_\n",
    "    \n",
    "    # Load Model lên GPU/CPU\n",
    "    model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"\\n>>> ĐANG CHẠY WEBCAM (Nhấn ESC để thoát)...\")\n",
    "    \n",
    "    # 2. Khởi tạo MediaPipe\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1, \n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as face_mesh:\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            h, w, _ = frame.shape\n",
    "            \n",
    "            # MediaPipe cần ảnh RGB\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            res = face_mesh.process(rgb)\n",
    "            \n",
    "            if res.multi_face_landmarks:\n",
    "                # Lấy khuôn mặt đầu tiên\n",
    "                face_landmarks = res.multi_face_landmarks[0]\n",
    "                \n",
    "                lm_list = []\n",
    "                x_list = []\n",
    "                y_list = []\n",
    "\n",
    "                # --- VÒNG LẶP XỬ LÝ ĐIỂM ---\n",
    "                for i, lm in enumerate(face_landmarks.landmark):\n",
    "                    # Chỉ lấy 468 điểm chính (bỏ qua phần mống mắt nếu có)\n",
    "                    if i >= 468: break\n",
    "                    \n",
    "                    # 1. Lưu tọa độ để dự đoán\n",
    "                    lm_list.extend([lm.x, lm.y])\n",
    "                    \n",
    "                    # 2. Tính tọa độ pixel để vẽ\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    x_list.append(cx)\n",
    "                    y_list.append(cy)\n",
    "                    \n",
    "                    # 3. VẼ ĐIỂM (LANDMARK)\n",
    "                    # Vẽ chấm nhỏ màu vàng (BGR: 0, 255, 255), kích thước 1\n",
    "                    cv2.circle(frame, (cx, cy), 1, (0, 255, 255), -1)\n",
    "\n",
    "                # --- TÍNH TOÁN DỰ ĐOÁN ---\n",
    "                lm_raw = np.array(lm_list, dtype=np.float32)\n",
    "                \n",
    "                # A. Feature Shape\n",
    "                lm_cs = center_scale_landmarks(lm_raw)\n",
    "                shape_vec = scaler.transform(pca.transform(lm_cs)).flatten()\n",
    "                shape_tensor = torch.tensor(shape_vec, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                # B. Feature Image (Warp Face)\n",
    "                # Lưu ý: lm_raw/48.0 vì hàm warp của mình mong đợi input normalized [0-1] nhưng scale theo size 48\n",
    "                # (Logic này phải khớp với lúc train, ở đây ta giả lập lại logic đó)\n",
    "                # Tuy nhiên, cách chuẩn nhất là dùng lm_list (0-1) trực tiếp. \n",
    "                # Sửa lại đoạn này cho khớp logic warp_face_mp:\n",
    "                lm_norm_warp = np.array(lm_list, dtype=np.float32) # Đây là 0.0 - 1.0\n",
    "                warp = warp_face_mp(frame, lm_norm_warp, mean_shape, IMG_SIZE) \n",
    "                \n",
    "                img_tensor = torch.tensor(warp, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                # C. Dự đoán\n",
    "                with torch.no_grad():\n",
    "                    out = model(img_tensor, shape_tensor)\n",
    "                    prob = F.softmax(out, dim=1)\n",
    "                    val, idx = torch.max(prob, 1)\n",
    "                    \n",
    "                emotion = EMOTION_LABELS[idx.item()]\n",
    "                score = val.item()\n",
    "                \n",
    "                # --- VẼ GIAO DIỆN (UI) ---\n",
    "                # Vẽ khung chữ nhật quanh mặt\n",
    "                x_min, x_max = min(x_list), max(x_list)\n",
    "                y_min, y_max = min(y_list), max(y_list)\n",
    "                \n",
    "                # Chọn màu theo cảm xúc (Vui/Bth: Xanh, Khác: Đỏ)\n",
    "                color = (0, 255, 0) if emotion in ['happy', 'neutral'] else (0, 0, 255)\n",
    "                \n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                \n",
    "                # Vẽ nhãn cảm xúc + thanh phần trăm\n",
    "                text = f\"{emotion.upper()}\"\n",
    "                cv2.putText(frame, text, (x_min, y_min - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "            cv2.imshow(\"PyTorch FER - MediaPipe\", frame)\n",
    "            if cv2.waitKey(1) == 27: break # ESC để thoát\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f76d4",
   "metadata": {},
   "source": [
    "## LƯỚI TAM GIÁC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b22494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_webcam():\n",
    "#     # 1. Load các tài nguyên\n",
    "#     if not os.path.exists(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\"): \n",
    "#         print(\"LỖI: Chưa có file model PyTorch.\")\n",
    "#         return\n",
    "    \n",
    "#     pca = joblib.load(\"model_mp_main_tot_nhat/shape_pca.pkl\")\n",
    "#     scaler = joblib.load(\"model_mp_main_tot_nhat/shape_scaler.pkl\")\n",
    "#     mean_shape = joblib.load(\"model_mp_main_tot_nhat/mean_shape.pkl\")\n",
    "#     shape_dim = pca.n_components_\n",
    "    \n",
    "#     # Load Model\n",
    "#     model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "#     model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n",
    "#     model.eval()\n",
    "    \n",
    "#     print(\"\\n>>> ĐANG CHẠY WEBCAM (Nhấn ESC để thoát)...\")\n",
    "    \n",
    "#     # --- CẤU HÌNH VẼ MEDIAPIPE ---\n",
    "#     mp_face_mesh = mp.solutions.face_mesh\n",
    "#     mp_drawing = mp.solutions.drawing_utils\n",
    "#     mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    \n",
    "#     cap = cv2.VideoCapture(0)\n",
    "    \n",
    "#     with mp_face_mesh.FaceMesh(\n",
    "#         max_num_faces=1, \n",
    "#         refine_landmarks=True,\n",
    "#         min_detection_confidence=0.5,\n",
    "#         min_tracking_confidence=0.5\n",
    "#     ) as face_mesh:\n",
    "        \n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret: break\n",
    "#             h, w, _ = frame.shape\n",
    "            \n",
    "#             rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             res = face_mesh.process(rgb)\n",
    "            \n",
    "#             if res.multi_face_landmarks:\n",
    "#                 face_landmarks = res.multi_face_landmarks[0]\n",
    "                \n",
    "#                 # --- A. THU THẬP DỮ LIỆU ĐỂ DỰ ĐOÁN (Giữ nguyên logic cũ) ---\n",
    "#                 lm_list = []\n",
    "#                 x_list = []\n",
    "#                 y_list = []\n",
    "\n",
    "#                 for i, lm in enumerate(face_landmarks.landmark):\n",
    "#                     if i >= 468: break\n",
    "#                     lm_list.extend([lm.x, lm.y])\n",
    "                    \n",
    "#                     # Lưu tọa độ để vẽ khung chữ nhật bao quanh mặt\n",
    "#                     cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "#                     x_list.append(cx)\n",
    "#                     y_list.append(cy)\n",
    "                    \n",
    "#                     # KHÔNG VẼ cv2.circle Ở ĐÂY NỮA\n",
    "\n",
    "#                 # --- B. VẼ LƯỚI TAM GIÁC (MESH) ---\n",
    "#                 # Vẽ lưới tam giác (Tesselation)\n",
    "#                 mp_drawing.draw_landmarks(\n",
    "#                     image=frame,\n",
    "#                     landmark_list=face_landmarks,\n",
    "#                     connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "#                     landmark_drawing_spec=None,\n",
    "#                     connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "#                 )\n",
    "                \n",
    "#                 # Vẽ đường bao (Mắt, môi, khuôn mặt) cho rõ nét hơn\n",
    "#                 mp_drawing.draw_landmarks(\n",
    "#                     image=frame,\n",
    "#                     landmark_list=face_landmarks,\n",
    "#                     connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "#                     landmark_drawing_spec=None,\n",
    "#                     connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "#                 )\n",
    "\n",
    "#                 # --- C. TÍNH TOÁN DỰ ĐOÁN (MODEL AI) ---\n",
    "#                 lm_raw = np.array(lm_list, dtype=np.float32)\n",
    "                \n",
    "#                 # Feature Shape\n",
    "#                 lm_cs = center_scale_landmarks(lm_raw)\n",
    "#                 shape_vec = scaler.transform(pca.transform(lm_cs)).flatten()\n",
    "#                 shape_tensor = torch.tensor(shape_vec, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "#                 # Feature Image (Warp Face)\n",
    "#                 lm_norm_warp = np.array(lm_list, dtype=np.float32)\n",
    "#                 warp = warp_face_mp(frame, lm_norm_warp, mean_shape, IMG_SIZE) \n",
    "#                 img_tensor = torch.tensor(warp, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "#                 # Inference\n",
    "#                 with torch.no_grad():\n",
    "#                     out = model(img_tensor, shape_tensor)\n",
    "#                     prob = F.softmax(out, dim=1)\n",
    "#                     val, idx = torch.max(prob, 1)\n",
    "                    \n",
    "#                 emotion = EMOTION_LABELS[idx.item()]\n",
    "#                 score = val.item()\n",
    "                \n",
    "#                 # --- D. VẼ UI KẾT QUẢ ---\n",
    "#                 x_min, x_max = min(x_list), max(x_list)\n",
    "#                 y_min, y_max = min(y_list), max(y_list)\n",
    "                \n",
    "#                 color = (0, 255, 0) if emotion in ['happy', 'neutral'] else (0, 0, 255)\n",
    "                \n",
    "#                 # Vẽ khung bao quanh mặt\n",
    "#                 cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "                \n",
    "#                 # Vẽ nhãn nền đen chữ màu\n",
    "#                 cv2.rectangle(frame, (x_min, y_min - 40), (x_max, y_min), color, -1)\n",
    "#                 text = f\"{emotion.upper()}\"\n",
    "#                 cv2.putText(frame, text, (x_min + 5, y_min - 10), \n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "#             cv2.imshow(\"PyTorch FER - Face Mesh\", frame)\n",
    "#             if cv2.waitKey(1) == 27: break # ESC\n",
    "            \n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b283db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path):\n",
    "    \"\"\"\n",
    "    Hàm nhận vào đường dẫn ảnh, dự đoán cảm xúc và hiển thị kết quả.\n",
    "    \"\"\"\n",
    "    # 1. KIỂM TRA TÀI NGUYÊN\n",
    "    required_files = [\n",
    "        \"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\",\n",
    "        \"model_mp_main_tot_nhat/shape_pca.pkl\",\n",
    "        \"model_mp_main_tot_nhat/shape_scaler.pkl\",\n",
    "        \"model_mp_main_tot_nhat/mean_shape.pkl\"\n",
    "    ]\n",
    "    \n",
    "    for f in required_files:\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"LỖI: Không tìm thấy file {f}. Hãy train model trước!\")\n",
    "            return\n",
    "\n",
    "    # 2. LOAD TÀI NGUYÊN\n",
    "    print(\">>> Đang load model và tài nguyên...\")\n",
    "    pca = joblib.load(\"model_mp_main_tot_nhat/shape_pca.pkl\")\n",
    "    scaler = joblib.load(\"model_mp_main_tot_nhat/shape_scaler.pkl\")\n",
    "    mean_shape = joblib.load(\"model_mp_main_tot_nhat/mean_shape.pkl\")\n",
    "    \n",
    "    # Load Model Structure & Weights\n",
    "    shape_dim = pca.n_components_\n",
    "    model = HybridModel(shape_input_dim=shape_dim).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    # 3. ĐỌC ẢNH & MEDIAPIPE\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"LỖI: Không đọc được ảnh. Kiểm tra lại đường dẫn.\")\n",
    "        return\n",
    "\n",
    "    # Resize ảnh nếu quá lớn để xử lý nhanh hơn\n",
    "    if img.shape[1] > 1000:\n",
    "        scale_percent = 50 \n",
    "        width = int(img.shape[1] * scale_percent / 100)\n",
    "        height = int(img.shape[0] * scale_percent / 100)\n",
    "        img = cv2.resize(img, (width, height))\n",
    "\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    \n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True, # Chế độ ảnh tĩnh (chính xác hơn webcam)\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as face_mesh:\n",
    "        \n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_img)\n",
    "        \n",
    "        if not results.multi_face_landmarks:\n",
    "            print(\"KHÔNG TÌM THẤY KHUÔN MẶT TRONG ẢNH!\")\n",
    "            cv2.imshow(\"Result\", img)\n",
    "            cv2.waitKey(0)\n",
    "            return\n",
    "\n",
    "        # Lấy khuôn mặt đầu tiên\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        h, w, _ = img.shape\n",
    "        \n",
    "        # Trích xuất 468 điểm\n",
    "        lm_list = []      # Dùng cho tính toán (0.0 - 1.0)\n",
    "        draw_points = []  # Dùng để vẽ (pixel)\n",
    "        \n",
    "        for i, lm in enumerate(face_landmarks.landmark):\n",
    "            if i >= 468: break\n",
    "            lm_list.extend([lm.x, lm.y])\n",
    "            draw_points.append((int(lm.x * w), int(lm.y * h)))\n",
    "\n",
    "        # 4. TIỀN XỬ LÝ (PREPROCESSING)\n",
    "        lm_raw = np.array(lm_list, dtype=np.float32)\n",
    "\n",
    "        # A. Shape Feature\n",
    "        lm_cs = center_scale_landmarks(lm_raw)\n",
    "        shape_vec = scaler.transform(pca.transform(lm_cs)).flatten()\n",
    "        shape_tensor = torch.tensor(shape_vec, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # B. Image Feature (Warp)\n",
    "        # Lưu ý: warp_face_mp cần input là (0-1) nếu mean_shape đã chuẩn hóa\n",
    "        warp = warp_face_mp(img, lm_raw, mean_shape, IMG_SIZE)\n",
    "        img_tensor = torch.tensor(warp, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # 5. DỰ ĐOÁN (INFERENCE)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor, shape_tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            score, predicted_idx = torch.max(probs, 1)\n",
    "            \n",
    "        emotion = EMOTION_LABELS[predicted_idx.item()]\n",
    "        confidence = score.item() * 100\n",
    "\n",
    "        # 6. HIỂN THỊ KẾT QUẢ\n",
    "        print(f\"\\n>>> KẾT QUẢ: {emotion.upper()} ({confidence:.2f}%)\")\n",
    "        print(\"    (Nhấn phím bất kỳ trên cửa sổ ảnh để đóng)\")\n",
    "\n",
    "        # Vẽ Landmarks\n",
    "        for (cx, cy) in draw_points:\n",
    "            cv2.circle(img, (cx, cy), 1, (0, 255, 255), -1)\n",
    "\n",
    "        # Vẽ Text & Hộp thông tin\n",
    "        cv2.rectangle(img, (0, 0), (300, 60), (0, 0, 0), -1)\n",
    "        cv2.putText(img, f\"Pred: {emotion.upper()}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"Conf: {confidence:.2f}%\", (10, 55), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "\n",
    "        cv2.imshow(\"Prediction Result\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PYTORCH FER HYBRID ---\n",
      "1. Train Model\n",
      "2. Evaluate on Test Set\n",
      "3. Predict Single Image (File)\n",
      "4. Webcam Demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6308\\128184203.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ĐANG CHẠY WEBCAM (Nhấn ESC để thoát)...\n",
      "\n",
      "--- PYTORCH FER HYBRID ---\n",
      "1. Train Model\n",
      "2. Evaluate on Test Set\n",
      "3. Predict Single Image (File)\n",
      "4. Webcam Demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6308\\128184203.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_mp_main_tot_nhat/hybrid_model_pytorch.pth\", map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ĐANG CHẠY WEBCAM (Nhấn ESC để thoát)...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        print(\"\\n--- PYTORCH FER HYBRID ---\")\n",
    "        print(\"1. Train Model\")\n",
    "        print(\"2. Evaluate on Test Set\")\n",
    "        print(\"3. Predict Single Image (File)\")  # <--- Mới\n",
    "        print(\"4. Webcam Demo\")\n",
    "        \n",
    "        choice = input(\"Chọn chức năng: \")\n",
    "        \n",
    "        if choice == '1': \n",
    "            train_pipeline()\n",
    "        elif choice == '2': \n",
    "            evaluate_performance()\n",
    "        elif choice == '3':\n",
    "            path = input(\"Nhập đường dẫn ảnh (VD: test.jpg): \")\n",
    "            # Xóa dấu ngoặc kép nếu người dùng copy path có dấu \"\"\n",
    "            path = path.strip('\"') \n",
    "            predict_single_image(path)\n",
    "        elif choice == '4': \n",
    "            run_webcam()\n",
    "        else: \n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
