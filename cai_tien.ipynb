{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aab4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55e2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình\n",
    "# ---------------------------\n",
    "EMOTION_LABELS = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "LANDMARK_START_COL = 4  # column chứa landmark đầu tiên trong CSV\n",
    "TRAIN_CSV = \"dataset_csv/fer2013_train.csv\"\n",
    "TEST_CSV  = \"dataset_csv/fer2013_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9ccecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_scale_landmarks(X):\n",
    "    X_cs = []\n",
    "    for s in X:\n",
    "        xs = s[::2]\n",
    "        ys = s[1::2]\n",
    "        cx, cy = xs.mean(), ys.mean()\n",
    "        xs = xs - cx\n",
    "        ys = ys - cy\n",
    "        scale = max(xs.max()-xs.min(), ys.max()-ys.min())\n",
    "        xs /= scale\n",
    "        ys /= scale\n",
    "        X_cs.append(np.column_stack([xs, ys]).flatten())\n",
    "    return np.array(X_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf73b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_to_mean_shape(img, src_lms, mean_lms, img_size=(48,48)):\n",
    "    \"\"\"\n",
    "    img: BGR image\n",
    "    src_lms: landmarks (x1,y1,...x68,y68) normalized [0,1]\n",
    "    mean_lms: landmarks mean shape normalized [0,1]\n",
    "    img_size: output warp size\n",
    "    \"\"\"\n",
    "    # Chuẩn bị điểm\n",
    "    src_pts = np.array(src_lms).reshape(-1,2) * img_size[0]\n",
    "    dst_pts = np.array(mean_lms).reshape(-1,2) * img_size[0]\n",
    "\n",
    "    # Affine warp mỗi tam giác Delaunay\n",
    "    import cv2, scipy.spatial\n",
    "    # Tạo mask\n",
    "    h, w = img_size\n",
    "    warp_img = np.zeros((h, w), dtype=np.uint8)\n",
    "    # Resize gốc về 48x48 grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = cv2.resize(img_gray, img_size)\n",
    "\n",
    "    # Sử dụng cv2.estimateAffinePartial2D cho toàn bộ shape\n",
    "    M, _ = cv2.estimateAffinePartial2D(src_pts, dst_pts)\n",
    "    if M is not None:\n",
    "        warp_img = cv2.warpAffine(img_gray, M, img_size)\n",
    "    else:\n",
    "        warp_img = img_gray\n",
    "\n",
    "    return warp_img.flatten() / 255.0  # flatten + normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef84a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV, header=None)\n",
    "X_train_raw = df_train.iloc[:, LANDMARK_START_COL:].values.astype(np.float32)\n",
    "y_train = df_train.iloc[:,2].values\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV, header=None)\n",
    "X_test_raw = df_test.iloc[:, LANDMARK_START_COL:].values.astype(np.float32)\n",
    "y_test = df_test.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f787f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shape = center_scale_landmarks(X_train_raw)\n",
    "pca_shape = PCA(n_components=0.95)\n",
    "X_train_shape_pca = pca_shape.fit_transform(X_train_shape)\n",
    "\n",
    "X_test_shape = center_scale_landmarks(X_test_raw)\n",
    "X_test_shape_pca = pca_shape.transform(X_test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c50872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shape = X_train_shape.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebc0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_appearance_matrix(df, mean_shape, img_size=(48,48)):\n",
    "    X_app = []\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = row[0]\n",
    "        lms = row[LANDMARK_START_COL:].values.astype(np.float32)\n",
    "        # normalize landmarks\n",
    "        lms_norm = lms / 48.0\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            warp = warp_to_mean_shape(img, lms_norm, mean_shape, img_size)\n",
    "            X_app.append(warp)\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(X_app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c881a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_app = build_appearance_matrix(df_train, mean_shape)\n",
    "X_test_app  = build_appearance_matrix(df_test, mean_shape)\n",
    "\n",
    "pca_app = PCA(n_components=0.95)\n",
    "X_train_app_pca = pca_app.fit_transform(X_train_app)\n",
    "X_test_app_pca = pca_app.transform(X_test_app)\n",
    "\n",
    "# ---------------------------\n",
    "# Kết hợp Shape + Appearance\n",
    "# ---------------------------\n",
    "X_train_combined = np.hstack([X_train_shape_pca, X_train_app_pca])\n",
    "X_test_combined  = np.hstack([X_test_shape_pca, X_test_app_pca])\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "X_test_combined  = scaler.transform(X_test_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4d346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/combined_scaler.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(128,64), max_iter=500)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "print(\"Training done!\")\n",
    "\n",
    "# Lưu model\n",
    "joblib.dump(clf, \"model/emotion_aam_mlp.pkl\")\n",
    "joblib.dump(pca_shape, \"model/shape_pca.pkl\")\n",
    "joblib.dump(pca_app, \"model/appearance_pca.pkl\")\n",
    "joblib.dump(scaler, \"model/combined_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cadd5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_aam_demo():\n",
    "    mp_face = mp.solutions.face_mesh\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_face.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = face_mesh.process(img_rgb)\n",
    "            \n",
    "            if result.multi_face_landmarks:\n",
    "                h, w, _ = frame.shape\n",
    "                for face_landmarks in result.multi_face_landmarks:\n",
    "                    # Draw landmarks\n",
    "                    for lm in face_landmarks.landmark:\n",
    "                        x, y = int(lm.x*w), int(lm.y*h)\n",
    "                        cv2.circle(frame, (x,y), 1, (0,255,0), -1)\n",
    "                    \n",
    "                    # Prepare landmarks\n",
    "                    lms = []\n",
    "                    for lm in face_landmarks.landmark:\n",
    "                        lms.append(lm.x)\n",
    "                        lms.append(lm.y)\n",
    "                    lms = np.array(lms).reshape(1,-1)\n",
    "                    lms_cs = center_scale_landmarks(lms)\n",
    "                    lms_pca = pca_shape.transform(lms_cs)\n",
    "                    \n",
    "                    # Appearance\n",
    "                    warp = warp_to_mean_shape(frame, lms, mean_shape, (48,48))\n",
    "                    warp_pca = pca_app.transform(warp.reshape(1,-1))\n",
    "                    \n",
    "                    # Combine\n",
    "                    x_combined = np.hstack([lms_pca, warp_pca])\n",
    "                    x_combined = scaler.transform(x_combined)\n",
    "                    \n",
    "                    # Predict\n",
    "                    proba = clf.predict_proba(x_combined)[0]\n",
    "                    pred_id = np.argmax(proba)\n",
    "                    pred_emotion = EMOTION_LABELS[pred_id]\n",
    "                    pred_conf = proba[pred_id]\n",
    "                    \n",
    "                    # Display\n",
    "                    text = f\"{pred_emotion} ({pred_conf*100:.1f}%)\"\n",
    "                    cv2.putText(frame, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,255), 3)\n",
    "            \n",
    "            cv2.imshow(\"AAM Emotion Recognition\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb463fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    webcam_aam_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
