{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5601e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b86e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset/emotion\"\n",
    "OUTPUT_CSV = \"fer2013_mp_landmarks.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d123cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "emotion_map = {emo:i for i,emo in enumerate(EMOTIONS)}\n",
    "\n",
    "mp_face = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f413a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image_path, img_size=48):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    # Convert BGR -> RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_face.FaceMesh(static_image_mode=True,\n",
    "                          max_num_faces=1,\n",
    "                          refine_landmarks=False,\n",
    "                          min_detection_confidence=0.5) as face_mesh:\n",
    "        result = face_mesh.process(img_rgb)\n",
    "\n",
    "        if not result.multi_face_landmarks:\n",
    "            return None\n",
    "\n",
    "        landmarks = []\n",
    "        for lm in result.multi_face_landmarks[0].landmark:\n",
    "            # Scale x, y về kích thước ảnh\n",
    "            landmarks.append(int(lm.x * img_size))\n",
    "            landmarks.append(int(lm.y * img_size))\n",
    "\n",
    "        return landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "104c4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [01:14<00:00, 53.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train disgust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436/436 [00:08<00:00, 52.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train fear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4097/4097 [01:18<00:00, 52.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7215/7215 [02:38<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4965/4965 [01:33<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4830/4830 [01:31<00:00, 52.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: train surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [01:03<00:00, 49.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [00:19<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test disgust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:02<00:00, 49.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test fear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:22<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test happy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1774/1774 [00:41<00:00, 42.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1233/1233 [00:24<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1247/1247 [00:25<00:00, 49.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: test surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 831/831 [00:16<00:00, 51.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Saved: fer2013_mp_landmarks.csv\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for subset in ['train','test']:\n",
    "    for emotion in EMOTIONS:\n",
    "        folder = os.path.join(DATASET_DIR, subset, emotion)\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "        \n",
    "        print(\"Processing:\", subset, emotion)\n",
    "        for img_name in tqdm(os.listdir(folder)):\n",
    "            if not img_name.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            lms = get_landmarks(img_path, img_size=48)\n",
    "            \n",
    "            if lms is not None:\n",
    "                row = [img_path, subset, emotion_map[emotion], emotion] + lms\n",
    "                data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"DONE! Saved:\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79e589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
